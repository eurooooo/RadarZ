"""ReAct æ¡†æ¶çš„èŠ‚ç‚¹å®ç°

åŒ…å«ä¸‰ä¸ªæ ¸å¿ƒèŠ‚ç‚¹ï¼š
1. think - æ€è€ƒä¸‹ä¸€æ­¥è¡ŒåŠ¨
2. act - æ‰§è¡ŒåŠ¨ä½œï¼ˆæœç´¢ã€è¿‡æ»¤ã€æ€»ç»“ï¼‰
3. observe - è§‚å¯Ÿç»“æœå¹¶æ›´æ–°çŠ¶æ€
"""

import os
from datetime import datetime
from pathlib import Path
from typing import Dict, Any, List
from langchain.chat_models import init_chat_model
from tavily import TavilyClient

from .state import ReActState
from .schemas import ThoughtAction, SearchQueryList, RelevanceAssessmentList, FinalSummary
from .prompts import (
    react_system_prompt,
    search_query_prompt,
    relevance_assessment_prompt,
    final_summary_prompt
)

MODEL_NAME = os.getenv("MODEL_NAME")
MODEL_PROVIDER = os.getenv("MODEL_PROVIDER") or None

def get_llm():
    return init_chat_model(model=MODEL_NAME, model_provider=MODEL_PROVIDER, temperature=0)


def think(state: ReActState) -> ReActState:
    """æ€è€ƒèŠ‚ç‚¹ï¼šåˆ†æå½“å‰çŠ¶æ€ï¼Œå†³å®šä¸‹ä¸€æ­¥è¡ŒåŠ¨
    
    è¿™æ˜¯ ReAct æ¡†æ¶çš„æ ¸å¿ƒï¼ŒAgent ä¼šæ€è€ƒï¼š
    - å½“å‰å·²ç»æ”¶é›†äº†ä»€ä¹ˆä¿¡æ¯
    - è¿˜éœ€è¦ä»€ä¹ˆä¿¡æ¯
    - ä¸‹ä¸€æ­¥åº”è¯¥æ‰§è¡Œä»€ä¹ˆåŠ¨ä½œ
    """
    # æ„å»ºå·²å®Œæˆæ­¥éª¤çš„æè¿°
    completed_steps = []
    if state.get('search_queries'):
        completed_steps.append(f"å·²ç”Ÿæˆ {len(state['search_queries'])} ä¸ªæœç´¢æŸ¥è¯¢")
    if state.get('search_results'):
        completed_steps.append(f"å·²æ”¶é›† {len(state['search_results'])} ä¸ªæœç´¢ç»“æœ")
    if state.get('filtered_results'):
        completed_steps.append(f"å·²è¿‡æ»¤å¾—åˆ° {len(state['filtered_results'])} ä¸ªç›¸å…³ç»“æœ")
    if not completed_steps:
        completed_steps.append("åˆšå¼€å§‹ï¼Œå°šæœªæ‰§è¡Œä»»ä½•æ­¥éª¤")
    
    # å‡†å¤‡æç¤ºè¯
    messages = react_system_prompt.format_messages(
        project_name=state['project_name'],
        readme=state['readme'],
        completed_steps="; ".join(completed_steps),
        search_results_count=len(state.get('search_results', [])),
        filtered_results_count=len(state.get('filtered_results', [])),
        step_count=state.get('step_count', 0),
        max_steps=state.get('max_steps', 10)
    )
    
    # è°ƒç”¨ LLM è¿›è¡Œæ€è€ƒ
    llm = get_llm()
    response = llm.with_structured_output(ThoughtAction).invoke(messages)
    
    # è®°å½•æ€è€ƒå†…å®¹
    thought_text = f"æ­¥éª¤ {state.get('step_count', 0) + 1}: {response.thought}"
    print(f"ğŸ’­ {thought_text}")
    print(f"   ğŸ“‹ è¡ŒåŠ¨: {response.action}")
    if response.action_input:
        print(f"   ğŸ“¥ è¾“å…¥: {response.action_input}")
    
    # æ›´æ–°çŠ¶æ€
    return {
        'current_thought': response.thought,
        'current_action': response.action,
        'action_input': response.action_input,
        'thoughts': [thought_text],
        'should_continue': response.action != 'finish'
    }


def act(state: ReActState) -> ReActState:
    """è¡ŒåŠ¨èŠ‚ç‚¹ï¼šæ ¹æ®æ€è€ƒç»“æœæ‰§è¡Œç›¸åº”çš„åŠ¨ä½œ
    
    æ”¯æŒçš„åŠ¨ä½œï¼š
    - search: æ‰§è¡Œç½‘ç»œæœç´¢
    - filter: è¿‡æ»¤æœç´¢ç»“æœ
    - summarize: ç”Ÿæˆæœ€ç»ˆæ€»ç»“
    - finish: å®Œæˆä»»åŠ¡
    """
    action = state.get('current_action', '')
    
    print(f"ğŸ¬ æ‰§è¡ŒåŠ¨ä½œ: {action}")
    
    # æ ¹æ®åŠ¨ä½œç±»å‹æ‰§è¡Œç›¸åº”çš„æ“ä½œ
    if action == 'search':
        return _act_search(state)
    elif action == 'filter':
        return _act_filter(state)
    elif action == 'summarize':
        return _act_summarize(state)
    elif action == 'finish':
        return {'should_continue': False}
    else:
        # å¦‚æœæ²¡æœ‰æ˜ç¡®åŠ¨ä½œï¼Œæ ¹æ®çŠ¶æ€è‡ªåŠ¨å†³å®š
        if not state.get('search_queries'):
            return _act_search(state)
        elif not state.get('filtered_results') and state.get('search_results'):
            return _act_filter(state)
        elif not state.get('final_summary') and state.get('filtered_results'):
            return _act_summarize(state)
        else:
            return {'should_continue': False}


def _act_search(state: ReActState) -> ReActState:
    """æ‰§è¡Œæœç´¢åŠ¨ä½œï¼šç”Ÿæˆæœç´¢æŸ¥è¯¢å¹¶æ‰§è¡Œç½‘ç»œæœç´¢"""
    print(f"ğŸ” æ‰§è¡Œæœç´¢åŠ¨ä½œ...")

    # å¦‚æœä¹‹å‰å·²ç»æœç´¢è¿‡ï¼Œå°±ä¸å†é‡å¤æœç´¢ï¼Œç›´æ¥å¤ç”¨ç»“æœï¼ŒåŠ å¿«é€Ÿåº¦
    if state.get("search_results"):
        print("   â„¹ï¸ å·²æœ‰æœç´¢ç»“æœï¼Œæœ¬æ¬¡è·³è¿‡é‡æ–°æœç´¢")
        return {}
    
    # ç”Ÿæˆæœç´¢æŸ¥è¯¢
    messages = search_query_prompt.format_messages(
        project_name=state['project_name'],
        readme=state['readme']
    )
    
    llm = get_llm()
    response = llm.with_structured_output(SearchQueryList).invoke(messages)
    
    # åªä¿ç•™å‰ 1~2 ä¸ªæŸ¥è¯¢ï¼Œé¿å…ç”Ÿæˆå¤ªå¤šæŸ¥è¯¢å¯¼è‡´æœç´¢å¤ªæ…¢
    raw_queries = response.queries
    # å»é‡å¹¶ä¿è¯é¡ºåº
    seen = set()
    deduped = []
    for q in raw_queries:
        q = q.strip()
        if not q:
            continue
        if q in seen:
            continue
        seen.add(q)
        deduped.append(q)

    # æœ€å¤šåªç”¨ 2 ä¸ªæŸ¥è¯¢
    search_queries = deduped[:2] or [state["project_name"]]
    print(f"   âœ… ç”Ÿæˆæœç´¢æŸ¥è¯¢ï¼ˆå·²ç²¾ç®€ï¼‰: {search_queries}")
    
    # æ‰§è¡Œç½‘ç»œæœç´¢
    tavily_client = TavilyClient(api_key=os.getenv("TAVILY_API_KEY"))
    all_results = []
    
    for query in search_queries:
        print(f"   ğŸ” æœç´¢: {query}")
        try:
            results = tavily_client.search(
                query=query,
                # æ¯ä¸ªæŸ¥è¯¢æœ€å¤šæ‹¿å°‘é‡ç»“æœï¼Œé¿å…ç»“æœæ•°é‡çˆ†ç‚¸
                max_results=5,
                include_raw_content=True
            )
            search_results = results.get('results', [])
            all_results.extend(search_results)
            print(f"      âœ… æ‰¾åˆ° {len(search_results)} ä¸ªç»“æœ")
        except Exception as e:
            print(f"      âŒ æœç´¢å¤±è´¥: {e}")
    
    print(f"   âœ… æ€»å…±æ”¶é›†åˆ° {len(all_results)} ä¸ªæœç´¢ç»“æœ")
    
    return {
        'search_queries': search_queries,
        'search_results': all_results,
        'observations': [f"æ‰§è¡Œæœç´¢ï¼Œæ”¶é›†åˆ° {len(all_results)} ä¸ªæœç´¢ç»“æœ"]
    }


def _act_filter(state: ReActState) -> ReActState:
    """æ‰§è¡Œè¿‡æ»¤åŠ¨ä½œï¼šè¿‡æ»¤æ‰ä¸ç›¸å…³çš„æœç´¢ç»“æœ"""
    print(f"ğŸ” æ‰§è¡Œè¿‡æ»¤åŠ¨ä½œ...")
    
    results = state.get('search_results', [])
    if not results:
        print("   âš ï¸ æ²¡æœ‰æœç´¢ç»“æœéœ€è¦è¿‡æ»¤")
        return {'filtered_results': []}
    
    # ç®€åŒ–ç‰ˆè¿‡æ»¤é€»è¾‘ï¼šä¸ç”¨å†è°ƒç”¨ LLMï¼Œä¸€ä¸ªé¡¹ç›®ä¸€èˆ¬ä¹Ÿæ²¡é‚£ä¹ˆå¤šé«˜è´¨é‡å¤–éƒ¨ä¿¡æ¯
    # è§„åˆ™ï¼š
    # 1. åªå–å‰ N æ¡ç»“æœï¼ˆæŒ‰æœç´¢å¼•æ“æ’åºï¼‰ï¼ŒN é»˜è®¤ 20
    # 2. ä¼˜å…ˆä¿ç•™æ ‡é¢˜æˆ– URL ä¸­åŒ…å«é¡¹ç›®å / ä»“åº“åçš„ç»“æœ
    max_keep = 20
    project_name = state.get("project_name", "").lower()
    repo_short = project_name.split("/")[-1] if project_name else ""

    strong_match: List[Dict[str, Any]] = []
    weak_match: List[Dict[str, Any]] = []

    for r in results:
        title = str(r.get("title", "")).lower()
        url = str(r.get("url", "")).lower()
        content = str((r.get("raw_content") or r.get("content") or "")).lower()

        text = title + " " + url + " " + content
        # å¼ºåŒ¹é…ï¼šåŒ…å«å®Œæ•´ä»“åº“åæˆ–çŸ­å
        if project_name and project_name in text:
            strong_match.append(r)
        elif repo_short and repo_short in text:
            strong_match.append(r)
        else:
            weak_match.append(r)

    # å…ˆæ”¾å¼ºåŒ¹é…ï¼Œå†è¡¥å……å°‘é‡å¼±åŒ¹é…ï¼Œæœ€å¤š max_keep æ¡
    filtered: List[Dict[str, Any]] = (strong_match + weak_match)[:max_keep]

    print(
        f"   âœ… è¿‡æ»¤å®Œæˆï¼šå¼ºåŒ¹é… {len(strong_match)} æ¡ï¼Œæ€»å…±ä¿ç•™ {len(filtered)} æ¡ "
        f"(åŸå§‹ {len(results)} æ¡ï¼Œä»…ä¾æ®ç®€å•è§„åˆ™å¿«é€Ÿç­›é€‰ï¼Œä¸å†è°ƒç”¨ LLM)"
    )
    
    return {
        'filtered_results': filtered,
        'observations': [f"è¿‡æ»¤æœç´¢ç»“æœï¼Œä¿ç•™ {len(filtered)} ä¸ªç›¸å…³ç»“æœ"]
    }


def _act_summarize(state: ReActState) -> ReActState:
    """æ‰§è¡Œæ€»ç»“åŠ¨ä½œï¼šç”Ÿæˆæœ€ç»ˆçš„é¡¹ç›®æ€»ç»“"""
    print(f"ğŸ“ æ‰§è¡Œæ€»ç»“åŠ¨ä½œ...")
    
    filtered_results = state.get('filtered_results', [])
    
    # æ„å»ºæœç´¢ç»“æœçš„æ–‡æœ¬è¡¨ç¤º
    if filtered_results:
        results_text = "\n\n---\n\n".join([
            f"æ ‡é¢˜: {r.get('title', 'N/A')}\n"
            f"URL: {r.get('url', 'N/A')}\n"
            f"å†…å®¹: {(r.get('raw_content') or r.get('content') or 'N/A')[:2000]}"
            for r in filtered_results
        ])
    else:
        results_text = "æœªæ‰¾åˆ°ç›¸å…³çš„æœç´¢ç»“æœã€‚"
    
    # æ„å»ºæç¤ºè¯
    messages = final_summary_prompt.format_messages(
        project_name=state['project_name'],
        readme=state['readme'],
        filtered_results=results_text
    )
    
    # è°ƒç”¨ LLM ç”Ÿæˆæ€»ç»“
    llm = get_llm()
    response = llm.with_structured_output(FinalSummary).invoke(messages)
    
    final_summary = response.summary
    print(f"   âœ… ç”Ÿæˆæ€»ç»“ ({len(final_summary)} å­—ç¬¦)")
    
    # å°†æ€»ç»“å†™å…¥æ–‡ä»¶
    output_dir = Path(__file__).parent.parent.parent.parent / "summaries"
    output_dir.mkdir(exist_ok=True)
    
    # ç”Ÿæˆå®‰å…¨çš„æ–‡ä»¶å
    safe_project_name = state['project_name'].replace("/", "_").replace("\\", "_")
    safe_project_name = "".join(c for c in safe_project_name if c.isalnum() or c in ('_', '-', '.'))
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    filename = f"{safe_project_name}_react_{timestamp}.md"
    filepath = output_dir / filename
    
    # å†™å…¥æ–‡ä»¶
    with open(filepath, 'w', encoding='utf-8') as f:
        f.write(f"# {state['project_name']} (ReAct æ¡†æ¶)\n\n")
        f.write(f"**ç”Ÿæˆæ—¶é—´:** {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n\n")
        f.write("---\n\n")
        f.write(final_summary)
    
    print(f"   ğŸ’¾ æ€»ç»“å·²ä¿å­˜åˆ°: {filepath}")
    
    return {
        'final_summary': final_summary,
        'observations': [f"ç”Ÿæˆæœ€ç»ˆæ€»ç»“ï¼Œå…± {len(final_summary)} å­—ç¬¦"],
        'should_continue': False
    }


def observe(state: ReActState) -> ReActState:
    """è§‚å¯ŸèŠ‚ç‚¹ï¼šè§‚å¯Ÿè¡ŒåŠ¨ç»“æœï¼Œæ›´æ–°çŠ¶æ€ï¼Œå†³å®šæ˜¯å¦ç»§ç»­"""
    step_count = state.get('step_count', 0) + 1
    max_steps = state.get('max_steps', 10)
    
    # æ£€æŸ¥æ˜¯å¦åº”è¯¥ç»§ç»­
    should_continue = state.get('should_continue', True)
    
    # æ£€æŸ¥æ˜¯å¦è¶…è¿‡æœ€å¤§æ­¥éª¤æ•°
    if step_count >= max_steps:
        print(f"âš ï¸ å·²è¾¾åˆ°æœ€å¤§æ­¥éª¤æ•° {max_steps}ï¼Œåœæ­¢æ‰§è¡Œ")
        should_continue = False
    
    # å¦‚æœå·²ç»ç”Ÿæˆæ€»ç»“ï¼Œåˆ™å®Œæˆä»»åŠ¡
    if state.get('final_summary'):
        should_continue = False
    
    print(f"ğŸ‘ï¸ è§‚å¯Ÿç»“æœ - æ­¥éª¤ {step_count}/{max_steps}, ç»§ç»­: {should_continue}")
    
    return {
        'step_count': step_count,
        'should_continue': should_continue
    }


def should_continue(state: ReActState) -> str:
    """æ¡ä»¶å‡½æ•°ï¼šå†³å®šæ˜¯å¦ç»§ç»­æ‰§è¡Œ ReAct å¾ªç¯"""
    if not state.get('should_continue', True):
        return "end"
    
    # å¦‚æœå·²ç»ç”Ÿæˆæ€»ç»“ï¼Œç»“æŸ
    if state.get('final_summary'):
        return "end"
    
    # å¦‚æœè¶…è¿‡æœ€å¤§æ­¥éª¤æ•°ï¼Œç»“æŸ
    if state.get('step_count', 0) >= state.get('max_steps', 10):
        return "end"
    
    return "continue"

